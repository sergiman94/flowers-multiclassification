{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtPGh2MAVrVa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil\n",
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "#Â import maplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# import tfjs to export the model to a tf.js layers format\n",
        "import tensorflowjs as tfjs\n",
        "# import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "In order to build our image classifier, we can begin by downloading the flowers dataset. We first need to download the archive version of the dataset and after the download we are storing it to \"/tmp/\" directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPjfOmNVrVs"
      },
      "source": [
        "After downloading the dataset, we need to extract its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYmOylPlVrVt",
        "outputId": "989f06a2-686d-48ca-d70b-f6f755f137a5"
      },
      "outputs": [],
      "source": [
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, fname='flower_photos.tgz', extract=True)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yge5MKnnjMd"
      },
      "source": [
        "The dataset we downloaded contains images of 5 types of flowers:\n",
        "\n",
        "1. Rose\n",
        "2. Daisy\n",
        "3. Dandelion\n",
        "4. Sunflowers\n",
        "5. Tulips\n",
        "\n",
        "So, let's create the labels for these 5 classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiYVs1MEmNHf"
      },
      "outputs": [],
      "source": [
        "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-AL030LmcdD",
        "outputId": "59b67aec-9591-4a81-cef2-7773fa95f3c1"
      },
      "outputs": [],
      "source": [
        "for cl in classes:\n",
        "  img_path = os.path.join(base_dir, cl)\n",
        "  images = glob.glob(img_path + '/*.jpg')\n",
        "  print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  train, val = images[:round(len(images)*0.8)], images[round(len(images)*0.8):]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
        "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
        "    shutil.move(v, os.path.join(base_dir, 'val', cl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh68rmWspp0U",
        "outputId": "5d638fb2-aca9-40c4-e256-91f45fe1881c"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "total_train = len(os.listdir(train_dir))\n",
        "total_val = len(os.listdir(val_dir))\n",
        "\n",
        "print('total train', total_train)\n",
        "print('total val', total_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOoVpxFwVrWy"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyPkET61yMMX"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "IMG_SHAPE = 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC8fIsalVrXd"
      },
      "source": [
        "### Generate Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnr2xujaVrXe",
        "outputId": "cefb01a7-c7f7-4d8d-c641-ba08ff536a87"
      },
      "outputs": [],
      "source": [
        "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=45,\n",
        "                                     width_shift_range=.15,\n",
        "                                     height_shift_range=.15,\n",
        "                                     horizontal_flip=True,\n",
        "                                     zoom_range=0.5)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size, directory=train_dir, shuffle=True, target_size=(IMG_SHAPE,IMG_SHAPE), class_mode='sparse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW-pV5awVrXl"
      },
      "source": [
        "Let's visualize how a single image would look like 5 different times, when we pass these augmentations randomly to our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLiyWp7Jfqw7"
      },
      "outputs": [],
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "z2m68eMhVrXm",
        "outputId": "3bddc305-c134-4950-fa4d-da0546b7ca0a"
      },
      "outputs": [],
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99fDBt7VrXr"
      },
      "source": [
        "### Create a Data Generator for the Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54x0aNbKVrXr",
        "outputId": "aac80a71-319e-4eb5-8bc1-4acf07f1660f"
      },
      "outputs": [],
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size, directory=val_dir, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode='sparse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "# Create the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evjf8jZk2zi-"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(5),\n",
        "    tf.keras.layers.Softmax()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADWLqMSJcH3"
      },
      "source": [
        "# Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08rRJ0sn3Tb1",
        "outputId": "257dc3e7-45cf-4dad-b380-030f304c209f"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "tk5NT1PW3j_P",
        "outputId": "aefd01be-0ecc-4d87-beb0-3b4ae5b85d11"
      },
      "outputs": [],
      "source": [
        "epochs = 80\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(batch_size))),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(batch_size)))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "# Plot Training and Validation Graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualizing results of the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "8CfngybnFHQR",
        "outputId": "f8e0999d-1964-4369-e03f-c17cecadacdf"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# export to TF.js layers format\n",
        "tfjs.converters.save_keras_model(model, './flowers_multiclassification_model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zF9uvbXNVrVY",
        "UZZI6lNkVrVm",
        "UOoVpxFwVrWy",
        "wEgW4i18VrWZ",
        "DADWLqMSJcH3",
        "oub9RtoFVrWk",
        "LZPYT-EmVrWo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
